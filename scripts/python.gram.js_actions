file[mod_ty]: a=[statements] ENDMARKER { $B._PyPegen.make_module(p, a) }
interactive[mod_ty]: a=statement_newline { $B._PyAST.Interactive(a, p.arena) }
eval[mod_ty]: a=expressions NEWLINE* ENDMARKER { $B._PyAST.Expression(a, p.arena) }
func_type[mod_ty]: '(' a=[type_expressions] ')' '->' b=expression NEWLINE* ENDMARKER { $B._PyAST.FunctionType(a, b, p.arena) }
fstring[expr_ty]: star_expressions
statements[asdl_stmt_seq*]: a=statement+ { $B._PyPegen.seq_flatten(p, a) }
statement[asdl_stmt_seq*]: a=compound_stmt { $B._PyPegen.singleton_seq(p, a) } | a[asdl_stmt_seq*]=simple_stmts { a }
statement_newline[asdl_stmt_seq*]:
    | a=compound_stmt NEWLINE { $B._PyPegen.singleton_seq(p, a) }
    | simple_stmts
    | NEWLINE { $B._PyPegen.singleton_seq(p, CHECK($B.ast.stmt, $B._PyAST.Pass(EXTRA))) }
    | ENDMARKER { $B._PyPegen.interactive_exit(p) }
simple_stmts[asdl_stmt_seq*]:
    | a=simple_stmt !';' NEWLINE { $B._PyPegen.singleton_seq(p, a) } # Not needed, there for speedup
    | a[asdl_stmt_seq*]=';'.simple_stmt+ [';'] NEWLINE { a }
simple_stmt[stmt_ty] (memo):
    | assignment
    | e=star_expressions { $B._PyAST.Expr(e, EXTRA) }
    | &'return' return_stmt
    | &('import' | 'from') import_stmt
    | &'raise' raise_stmt
    | 'pass' { $B._PyAST.Pass(EXTRA) }
    | &'del' del_stmt
    | &'yield' yield_stmt
    | &'assert' assert_stmt
    | 'break' { $B._PyAST.Break(EXTRA) }
    | 'continue' { $B._PyAST.Continue(EXTRA) }
    | &'global' global_stmt
    | &'nonlocal' nonlocal_stmt
compound_stmt[stmt_ty]:
    | &('def' | '@' | ASYNC) function_def
    | &'if' if_stmt
    | &('class' | '@') class_def
    | &('with' | ASYNC) with_stmt
    | &('for' | ASYNC) for_stmt
    | &'try' try_stmt
    | &'while' while_stmt
    | match_stmt
assignment[stmt_ty]:
    | a=NAME ':' b=expression c=['=' d=annotated_rhs { d }] {
        CHECK_VERSION(
            $B.ast.stmt,
            6,
            "Variable annotation syntax is",
            $B._PyAST.AnnAssign(CHECK($B.ast.expr, $B._PyPegen.set_expr_context(p, a, Store)), b, c, 1, EXTRA)
        ) }
    | a=('(' b=single_target ')' { b }
         | single_subscript_attribute_target) ':' b=expression c=['=' d=annotated_rhs { d }] {
        CHECK_VERSION($B.ast.stmt, 6, "Variable annotations syntax is", $B._PyAST.AnnAssign(a, b, c, 0, EXTRA)) }
    | a[asdl_expr_seq*]=(z=star_targets '=' { z })+ b=(yield_expr | star_expressions) !'=' tc=[TYPE_COMMENT] {
         $B._PyAST.Assign(a, b, NEW_TYPE_COMMENT(p, tc), EXTRA) }
    | a=single_target b=augassign ~ c=(yield_expr | star_expressions) {
         $B._PyAST.AugAssign(a, b.kind, c, EXTRA) }
    | invalid_assignment
annotated_rhs[expr_ty]: yield_expr | star_expressions
augassign[AugOperator*]:
    | '+=' { $B._PyPegen.augoperator(p, Add) }
    | '-=' { $B._PyPegen.augoperator(p, Sub) }
    | '*=' { $B._PyPegen.augoperator(p, Mult) }
    | '@=' { CHECK_VERSION(AugOperator, 5, "The '@' operator is", $B._PyPegen.augoperator(p, MatMult)) }
    | '/=' { $B._PyPegen.augoperator(p, Div) }
    | '%=' { $B._PyPegen.augoperator(p, Mod) }
    | '&=' { $B._PyPegen.augoperator(p, BitAnd) }
    | '|=' { $B._PyPegen.augoperator(p, BitOr) }
    | '^=' { $B._PyPegen.augoperator(p, BitXor) }
    | '<<=' { $B._PyPegen.augoperator(p, LShift) }
    | '>>=' { $B._PyPegen.augoperator(p, RShift) }
    | '**=' { $B._PyPegen.augoperator(p, Pow) }
    | '//=' { $B._PyPegen.augoperator(p, FloorDiv) }
return_stmt[stmt_ty]:
    | 'return' a=[star_expressions] { $B._PyAST.Return(a, EXTRA) }
raise_stmt[stmt_ty]:
    | 'raise' a=expression b=['from' z=expression { z }] { $B._PyAST.Raise(a, b, EXTRA) }
    | 'raise' { $B._PyAST.Raise(NULL, NULL, EXTRA) }
global_stmt[stmt_ty]: 'global' a[asdl_expr_seq*]=','.NAME+ {
    $B._PyAST.Global(CHECK(asdl_identifier_seq, $B._PyPegen.map_names_to_ids(p, a)), EXTRA) }
nonlocal_stmt[stmt_ty]: 'nonlocal' a[asdl_expr_seq*]=','.NAME+ {
    $B._PyAST.Nonlocal(CHECK(asdl_identifier_seq, $B._PyPegen.map_names_to_ids(p, a)), EXTRA) }
del_stmt[stmt_ty]:
    | 'del' a=del_targets &(';' | NEWLINE) { $B._PyAST.Delete(a, EXTRA) }
    | invalid_del_stmt
yield_stmt[stmt_ty]: y=yield_expr { $B._PyAST.Expr(y, EXTRA) }
assert_stmt[stmt_ty]: 'assert' a=expression b=[',' z=expression { z }] { $B._PyAST.Assert(a, b, EXTRA) }
import_stmt[stmt_ty]: import_name | import_from
import_name[stmt_ty]: 'import' a=dotted_as_names { $B._PyAST.Import(a, EXTRA) }
import_from[stmt_ty]:
    | 'from' a=('.' | '...')* b=dotted_name 'import' c=import_from_targets {
        $B._PyAST.ImportFrom(b.id, c, $B._PyPegen.seq_count_dots(a), EXTRA) }
    | 'from' a=('.' | '...')+ 'import' b=import_from_targets {
        $B._PyAST.ImportFrom(NULL, b, $B._PyPegen.seq_count_dots(a), EXTRA) }
import_from_targets[asdl_alias_seq*]:
    | '(' a=import_from_as_names [','] ')' { a }
    | import_from_as_names !','
    | '*' { $B._PyPegen.singleton_seq(p, CHECK($B.ast.alias, $B._PyPegen.alias_for_star(p, EXTRA))) }
    | invalid_import_from_targets
import_from_as_names[asdl_alias_seq*]:
    | a[asdl_alias_seq*]=','.import_from_as_name+ { a }
import_from_as_name[alias_ty]:
    | a=NAME b=['as' z=NAME { z }] { $B._PyAST.alias(a.id,
                                               (b) ? b.id : NULL,
                                               EXTRA) }
dotted_as_names[asdl_alias_seq*]:
    | a[asdl_alias_seq*]=','.dotted_as_name+ { a }
dotted_as_name[alias_ty]:
    | a=dotted_name b=['as' z=NAME { z }] { $B._PyAST.alias(a.id,
                                                      (b) ? b.id : NULL,
                                                      EXTRA) }
dotted_name[expr_ty]:
    | a=dotted_name '.' b=NAME { $B._PyPegen.join_names_with_dot(p, a, b) }
    | NAME
block[asdl_stmt_seq*] (memo):
    | NEWLINE INDENT a=statements DEDENT { a }
    | simple_stmts
    | invalid_block
decorators[asdl_expr_seq*]: a[asdl_expr_seq*]=('@' f=named_expression NEWLINE { f })+ { a }
class_def[stmt_ty]:
    | a=decorators b=class_def_raw { $B._PyPegen.class_def_decorators(p, a, b) }
    | class_def_raw
class_def_raw[stmt_ty]:
    | invalid_class_def_raw
    | 'class' a=NAME b=['(' z=[arguments] ')' { z }] &&':' c=block {
        $B._PyAST.ClassDef(a.id,
                     (b) ? b.args : NULL,
                     (b) ? b.keywords : NULL,
                     c, NULL, EXTRA) }
function_def[stmt_ty]:
    | d=decorators f=function_def_raw { $B._PyPegen.function_def_decorators(p, d, f) }
    | function_def_raw
function_def_raw[stmt_ty]:
    | invalid_def_raw
    | 'def' n=NAME &&'(' params=[params] ')' a=['->' z=expression { z }] &&':' tc=[func_type_comment] b=block {
        $B._PyAST.FunctionDef(n.id,
                        (params) ? params : CHECK($B.ast.arguments, $B._PyPegen.empty_arguments(p)),
                        b, NULL, a, NEW_TYPE_COMMENT(p, tc), EXTRA) }
    | ASYNC 'def' n=NAME &&'(' params=[params] ')' a=['->' z=expression { z }] &&':' tc=[func_type_comment] b=block {
        CHECK_VERSION(
            $B.ast.stmt,
            5,
            "Async functions are",
            $B._PyAST.AsyncFunctionDef(n.id,
                            (params) ? params : CHECK($B.ast.arguments, $B._PyPegen.empty_arguments(p)),
                            b, NULL, a, NEW_TYPE_COMMENT(p, tc), EXTRA)
        ) }
params[arguments_ty]:
    | invalid_parameters
    | parameters
parameters[arguments_ty]:
    | a=slash_no_default b[asdl_arg_seq*]=param_no_default* c=param_with_default* d=[star_etc] {
        $B._PyPegen.make_arguments(p, a, NULL, b, c, d) }
    | a=slash_with_default b=param_with_default* c=[star_etc] {
        $B._PyPegen.make_arguments(p, NULL, a, NULL, b, c) }
    | a[asdl_arg_seq*]=param_no_default+ b=param_with_default* c=[star_etc] {
        $B._PyPegen.make_arguments(p, NULL, NULL, a, b, c) }
    | a=param_with_default+ b=[star_etc] { $B._PyPegen.make_arguments(p, NULL, NULL, NULL, a, b)}
    | a=star_etc { $B._PyPegen.make_arguments(p, NULL, NULL, NULL, NULL, a) }
slash_no_default[asdl_arg_seq*]:
    | a[asdl_arg_seq*]=param_no_default+ '/' ',' { a }
    | a[asdl_arg_seq*]=param_no_default+ '/' &')' { a }
slash_with_default[SlashWithDefault*]:
    | a=param_no_default* b=param_with_default+ '/' ',' { $B._PyPegen.slash_with_default(p, a, b) }
    | a=param_no_default* b=param_with_default+ '/' &')' { $B._PyPegen.slash_with_default(p, a, b) }
star_etc[StarEtc*]:
    | invalid_star_etc
    | '*' a=param_no_default b=param_maybe_default* c=[kwds] {
        $B._PyPegen.star_etc(p, a, b, c) }
    | '*' a=param_no_default_star_annotation b=param_maybe_default* c=[kwds] {
        $B._PyPegen.star_etc(p, a, b, c) }
    | '*' ',' b=param_maybe_default+ c=[kwds] {
        $B._PyPegen.star_etc(p, NULL, b, c) }
    | a=kwds { $B._PyPegen.star_etc(p, NULL, NULL, a) }
kwds[arg_ty]:
    | invalid_kwds
    | '**' a=param_no_default { a }
param_no_default[arg_ty]:
    | a=param ',' tc=TYPE_COMMENT? { $B._PyPegen.add_type_comment_to_arg(p, a, tc) }
    | a=param tc=TYPE_COMMENT? &')' { $B._PyPegen.add_type_comment_to_arg(p, a, tc) }
param_no_default_star_annotation[arg_ty]:
    | a=param_star_annotation ',' tc=TYPE_COMMENT? { $B._PyPegen.add_type_comment_to_arg(p, a, tc) }
    | a=param_star_annotation tc=TYPE_COMMENT? &')' { $B._PyPegen.add_type_comment_to_arg(p, a, tc) }
param_with_default[NameDefaultPair*]:
    | a=param c=default ',' tc=TYPE_COMMENT? { $B._PyPegen.name_default_pair(p, a, c, tc) }
    | a=param c=default tc=TYPE_COMMENT? &')' { $B._PyPegen.name_default_pair(p, a, c, tc) }
param_maybe_default[NameDefaultPair*]:
    | a=param c=default? ',' tc=TYPE_COMMENT? { $B._PyPegen.name_default_pair(p, a, c, tc) }
    | a=param c=default? tc=TYPE_COMMENT? &')' { $B._PyPegen.name_default_pair(p, a, c, tc) }
param[arg_ty]: a=NAME b=annotation? { $B._PyAST.arg(a.id, b, NULL, EXTRA) }
param_star_annotation[arg_ty]: a=NAME b=star_annotation { $B._PyAST.arg(a.id, b, NULL, EXTRA) }
annotation[expr_ty]: ':' a=expression { a }
star_annotation[expr_ty]: ':' a=star_expression { a }
default[expr_ty]: '=' a=expression { a } | invalid_default
if_stmt[stmt_ty]:
    | invalid_if_stmt
    | 'if' a=named_expression ':' b=block c=elif_stmt {
        $B._PyAST.If(a, b, CHECK(asdl_stmt_seq, $B._PyPegen.singleton_seq(p, c)), EXTRA) }
    | 'if' a=named_expression ':' b=block c=[else_block] { $B._PyAST.If(a, b, c, EXTRA) }
elif_stmt[stmt_ty]:
    | invalid_elif_stmt
    | 'elif' a=named_expression ':' b=block c=elif_stmt {
        $B._PyAST.If(a, b, CHECK(asdl_stmt_seq, $B._PyPegen.singleton_seq(p, c)), EXTRA) }
    | 'elif' a=named_expression ':' b=block c=[else_block] { $B._PyAST.If(a, b, c, EXTRA) }
else_block[asdl_stmt_seq*]:
    | invalid_else_stmt
    | 'else' &&':' b=block { b }
while_stmt[stmt_ty]:
    | invalid_while_stmt
    | 'while' a=named_expression ':' b=block c=[else_block] { $B._PyAST.While(a, b, c, EXTRA) }
for_stmt[stmt_ty]:
    | invalid_for_stmt
    | 'for' t=star_targets 'in' ~ ex=star_expressions &&':' tc=[TYPE_COMMENT] b=block el=[else_block] {
        $B._PyAST.For(t, ex, b, el, NEW_TYPE_COMMENT(p, tc), EXTRA) }
    | ASYNC 'for' t=star_targets 'in' ~ ex=star_expressions &&':' tc=[TYPE_COMMENT] b=block el=[else_block] {
        CHECK_VERSION($B.ast.stmt, 5, "Async for loops are", $B._PyAST.AsyncFor(t, ex, b, el, NEW_TYPE_COMMENT(p, tc), EXTRA)) }
    | invalid_for_target
with_stmt[stmt_ty]:
    | invalid_with_stmt_indent
    | 'with' '(' a[asdl_withitem_seq*]=','.with_item+ ','? ')' ':' b=block {
        $B._PyAST.With(a, b, NULL, EXTRA) }
    | 'with' a[asdl_withitem_seq*]=','.with_item+ ':' tc=[TYPE_COMMENT] b=block {
        $B._PyAST.With(a, b, NEW_TYPE_COMMENT(p, tc), EXTRA) }
    | ASYNC 'with' '(' a[asdl_withitem_seq*]=','.with_item+ ','? ')' ':' b=block {
       CHECK_VERSION($B.ast.stmt, 5, "Async with statements are", $B._PyAST.AsyncWith(a, b, NULL, EXTRA)) }
    | ASYNC 'with' a[asdl_withitem_seq*]=','.with_item+ ':' tc=[TYPE_COMMENT] b=block {
       CHECK_VERSION($B.ast.stmt, 5, "Async with statements are", $B._PyAST.AsyncWith(a, b, NEW_TYPE_COMMENT(p, tc), EXTRA)) }
    | invalid_with_stmt
with_item[withitem_ty]:
    | e=expression 'as' t=star_target &(',' | ')' | ':') { $B._PyAST.withitem(e, t, p.arena) }
    | invalid_with_item
    | e=expression { $B._PyAST.withitem(e, NULL, p.arena) }
try_stmt[stmt_ty]:
    | invalid_try_stmt
    | 'try' &&':' b=block f=finally_block { $B._PyAST.Try(b, NULL, NULL, f, EXTRA) }
    | 'try' &&':' b=block ex[asdl_excepthandler_seq*]=except_block+ el=[else_block] f=[finally_block] { $B._PyAST.Try(b, ex, el, f, EXTRA) }
    | 'try' &&':' b=block ex[asdl_excepthandler_seq*]=except_star_block+ el=[else_block] f=[finally_block] { $B._PyAST.TryStar(b, ex, el, f, EXTRA) }
except_block[excepthandler_ty]:
    | invalid_except_stmt_indent
    | 'except' e=expression t=['as' z=NAME { z }] ':' b=block {
        $B._PyAST.ExceptHandler(e, (t) ? t.id : NULL, b, EXTRA) }
    | 'except' ':' b=block { $B._PyAST.ExceptHandler(NULL, NULL, b, EXTRA) }
    | invalid_except_stmt
except_star_block[excepthandler_ty]:
    | invalid_except_star_stmt_indent
    | 'except' '*' e=expression t=['as' z=NAME { z }] ':' b=block {
        $B._PyAST.ExceptHandler(e, (t) ? t.id : NULL, b, EXTRA) }
    | invalid_except_stmt
finally_block[asdl_stmt_seq*]:
    | invalid_finally_stmt
    | 'finally' &&':' a=block { a }
match_stmt[stmt_ty]:
    | "match" subject=subject_expr ':' NEWLINE INDENT cases[asdl_match_case_seq*]=case_block+ DEDENT {
        CHECK_VERSION($B.ast.stmt, 10, "Pattern matching is", $B._PyAST.Match(subject, cases, EXTRA)) }
    | invalid_match_stmt
subject_expr[expr_ty]:
    | value=star_named_expression ',' values=star_named_expressions? {
        $B._PyAST.Tuple(CHECK(asdl_expr_seq, $B._PyPegen.seq_insert_in_front(p, value, values)), Load, EXTRA) }
    | named_expression
case_block[match_case_ty]:
    | invalid_case_block
    | "case" pattern=patterns guard=guard? ':' body=block {
        $B._PyAST.match_case(pattern, guard, body, p.arena) }
guard[expr_ty]: 'if' guard=named_expression { guard }
patterns[pattern_ty]:
    | patterns[asdl_pattern_seq*]=open_sequence_pattern {
        $B._PyAST.MatchSequence(patterns, EXTRA) }
    | pattern
pattern[pattern_ty]:
    | as_pattern
    | or_pattern
as_pattern[pattern_ty]:
    | pattern=or_pattern 'as' target=pattern_capture_target {
        $B._PyAST.MatchAs(pattern, target.id, EXTRA) }
    | invalid_as_pattern
or_pattern[pattern_ty]:
    | patterns[asdl_pattern_seq*]='|'.closed_pattern+ {
        asdl_seq_LEN(patterns) == 1 ? asdl_seq_GET(patterns, 0) : $B._PyAST.MatchOr(patterns, EXTRA) }
closed_pattern[pattern_ty]:
    | literal_pattern
    | capture_pattern
    | wildcard_pattern
    | value_pattern
    | group_pattern
    | sequence_pattern
    | mapping_pattern
    | class_pattern
literal_pattern[pattern_ty]:
    | value=signed_number !('+' | '-') { $B._PyAST.MatchValue(value, EXTRA) }
    | value=complex_number { $B._PyAST.MatchValue(value, EXTRA) }
    | value=strings { $B._PyAST.MatchValue(value, EXTRA) }
    | 'None' { $B._PyAST.MatchSingleton(Py_None, EXTRA) }
    | 'True' { $B._PyAST.MatchSingleton(Py_True, EXTRA) }
    | 'False' { $B._PyAST.MatchSingleton(Py_False, EXTRA) }
literal_expr[expr_ty]:
    | signed_number !('+' | '-')
    | complex_number
    | strings
    | 'None' { $B._PyAST.Constant(Py_None, NULL, EXTRA) }
    | 'True' { $B._PyAST.Constant(Py_True, NULL, EXTRA) }
    | 'False' { $B._PyAST.Constant(Py_False, NULL, EXTRA) }
complex_number[expr_ty]:
    | real=signed_real_number '+' imag=imaginary_number {
        $B._PyAST.BinOp(real, Add, imag, EXTRA) }
    | real=signed_real_number '-' imag=imaginary_number  {
        $B._PyAST.BinOp(real, Sub, imag, EXTRA) }
signed_number[expr_ty]:
    | NUMBER
    | '-' number=NUMBER { $B._PyAST.UnaryOp(USub, number, EXTRA) }
signed_real_number[expr_ty]:
    | real_number
    | '-' real=real_number { $B._PyAST.UnaryOp(USub, real, EXTRA) }
real_number[expr_ty]:
    | real=NUMBER { $B._PyPegen.ensure_real(p, real) }
imaginary_number[expr_ty]:
    | imag=NUMBER { $B._PyPegen.ensure_imaginary(p, imag) }
capture_pattern[pattern_ty]:
    | target=pattern_capture_target { $B._PyAST.MatchAs(NULL, target.id, EXTRA) }
pattern_capture_target[expr_ty]:
    | !"_" name=NAME !('.' | '(' | '=') {
        $B._PyPegen.set_expr_context(p, name, Store) }
wildcard_pattern[pattern_ty]:
    | "_" { $B._PyAST.MatchAs(NULL, NULL, EXTRA) }
value_pattern[pattern_ty]:
    | attr=attr !('.' | '(' | '=') { $B._PyAST.MatchValue(attr, EXTRA) }
attr[expr_ty]:
    | value=name_or_attr '.' attr=NAME {
        $B._PyAST.Attribute(value, attr.id, Load, EXTRA) }
name_or_attr[expr_ty]:
    | attr
    | NAME
group_pattern[pattern_ty]:
    | '(' pattern=pattern ')' { pattern }
sequence_pattern[pattern_ty]:
    | '[' patterns=maybe_sequence_pattern? ']' { $B._PyAST.MatchSequence(patterns, EXTRA) }
    | '(' patterns=open_sequence_pattern? ')' { $B._PyAST.MatchSequence(patterns, EXTRA) }
open_sequence_pattern[asdl_seq*]:
    | pattern=maybe_star_pattern ',' patterns=maybe_sequence_pattern? {
        $B._PyPegen.seq_insert_in_front(p, pattern, patterns) }
maybe_sequence_pattern[asdl_seq*]:
    | patterns=','.maybe_star_pattern+ ','? { patterns }
maybe_star_pattern[pattern_ty]:
    | star_pattern
    | pattern
star_pattern[pattern_ty]:
    | '*' target=pattern_capture_target {
        $B._PyAST.MatchStar(target.id, EXTRA) }
    | '*' wildcard_pattern {
        $B._PyAST.MatchStar(NULL, EXTRA) }
mapping_pattern[pattern_ty]:
    | '{' '}' {
        $B._PyAST.MatchMapping(NULL, NULL, NULL, EXTRA) }
    | '{' rest=double_star_pattern ','? '}' {
        $B._PyAST.MatchMapping(NULL, NULL, rest.id, EXTRA) }
    | '{' items=items_pattern ',' rest=double_star_pattern ','? '}' {
        $B._PyAST.MatchMapping(
            CHECK(asdl_expr_seq, $B._PyPegen.get_pattern_keys(p, items)),
            CHECK(asdl_pattern_seq, $B._PyPegen.get_patterns(p, items)),
            rest.id,
            EXTRA) }
    | '{' items=items_pattern ','? '}' {
        $B._PyAST.MatchMapping(
            CHECK(asdl_expr_seq, $B._PyPegen.get_pattern_keys(p, items)),
            CHECK(asdl_pattern_seq, $B._PyPegen.get_patterns(p, items)),
            NULL,
            EXTRA) }
items_pattern[asdl_seq*]:
    | ','.key_value_pattern+
key_value_pattern[KeyPatternPair*]:
    | key=(literal_expr | attr) ':' pattern=pattern {
        $B._PyPegen.key_pattern_pair(p, key, pattern) }
double_star_pattern[expr_ty]:
    | '**' target=pattern_capture_target { target }
class_pattern[pattern_ty]:
    | cls=name_or_attr '(' ')' {
        $B._PyAST.MatchClass(cls, NULL, NULL, NULL, EXTRA) }
    | cls=name_or_attr '(' patterns=positional_patterns ','? ')' {
        $B._PyAST.MatchClass(cls, patterns, NULL, NULL, EXTRA) }
    | cls=name_or_attr '(' keywords=keyword_patterns ','? ')' {
        $B._PyAST.MatchClass(
            cls, NULL,
            CHECK(asdl_identifier_seq, $B._PyPegen.map_names_to_ids(p,
                CHECK(asdl_expr_seq, $B._PyPegen.get_pattern_keys(p, keywords)))),
            CHECK(asdl_pattern_seq, $B._PyPegen.get_patterns(p, keywords)),
            EXTRA) }
    | cls=name_or_attr '(' patterns=positional_patterns ',' keywords=keyword_patterns ','? ')' {
        $B._PyAST.MatchClass(
            cls,
            patterns,
            CHECK(asdl_identifier_seq, $B._PyPegen.map_names_to_ids(p,
                CHECK(asdl_expr_seq, $B._PyPegen.get_pattern_keys(p, keywords)))),
            CHECK(asdl_pattern_seq, $B._PyPegen.get_patterns(p, keywords)),
            EXTRA) }
    | invalid_class_pattern
positional_patterns[asdl_pattern_seq*]:
    | args[asdl_pattern_seq*]=','.pattern+ { args }
keyword_patterns[asdl_seq*]:
    | ','.keyword_pattern+
keyword_pattern[KeyPatternPair*]:
    | arg=NAME '=' value=pattern { $B._PyPegen.key_pattern_pair(p, arg, value) }
expressions[expr_ty]:
    | a=expression b=(',' c=expression { c })+ [','] {
        $B._PyAST.Tuple(CHECK(asdl_expr_seq, $B._PyPegen.seq_insert_in_front(p, a, b)), Load, EXTRA) }
    | a=expression ',' { $B._PyAST.Tuple(CHECK(asdl_expr_seq, $B._PyPegen.singleton_seq(p, a)), Load, EXTRA) }
    | expression
expression[expr_ty] (memo):
    | invalid_expression
    | invalid_legacy_expression
    | a=disjunction 'if' b=disjunction 'else' c=expression { $B._PyAST.IfExp(b, a, c, EXTRA) }
    | disjunction
    | lambdef
yield_expr[expr_ty]:
    | 'yield' 'from' a=expression { $B._PyAST.YieldFrom(a, EXTRA) }
    | 'yield' a=[star_expressions] { $B._PyAST.Yield(a, EXTRA) }
star_expressions[expr_ty]:
    | a=star_expression b=(',' c=star_expression { c })+ [','] {
        $B._PyAST.Tuple(CHECK(asdl_expr_seq, $B._PyPegen.seq_insert_in_front(p, a, b)), Load, EXTRA) }
    | a=star_expression ',' { $B._PyAST.Tuple(CHECK(asdl_expr_seq, $B._PyPegen.singleton_seq(p, a)), Load, EXTRA) }
    | star_expression
star_expression[expr_ty] (memo):
    | '*' a=bitwise_or { $B._PyAST.Starred(a, Load, EXTRA) }
    | expression
star_named_expressions[asdl_expr_seq*]: a[asdl_expr_seq*]=','.star_named_expression+ [','] { a }
star_named_expression[expr_ty]:
    | '*' a=bitwise_or { $B._PyAST.Starred(a, Load, EXTRA) }
    | named_expression
assignment_expression[expr_ty]:
    | a=NAME ':=' ~ b=expression { $B._PyAST.NamedExpr(CHECK($B.ast.expr, $B._PyPegen.set_expr_context(p, a, Store)), b, EXTRA) }
named_expression[expr_ty]:
    | assignment_expression
    | invalid_named_expression
    | expression !':='
disjunction[expr_ty] (memo):
    | a=conjunction b=('or' c=conjunction { c })+ { $B._PyAST.BoolOp(
        Or,
        CHECK(asdl_expr_seq, $B._PyPegen.seq_insert_in_front(p, a, b)),
        EXTRA) }
    | conjunction
conjunction[expr_ty] (memo):
    | a=inversion b=('and' c=inversion { c })+ { $B._PyAST.BoolOp(
        And,
        CHECK(asdl_expr_seq, $B._PyPegen.seq_insert_in_front(p, a, b)),
        EXTRA) }
    | inversion
inversion[expr_ty] (memo):
    | 'not' a=inversion { $B._PyAST.UnaryOp(Not, a, EXTRA) }
    | comparison
comparison[expr_ty]:
    | a=bitwise_or b=compare_op_bitwise_or_pair+ {
        $B._PyAST.Compare(
            a,
            CHECK(asdl_int_seq, $B._PyPegen.get_cmpops(p, b)),
            CHECK(asdl_expr_seq, $B._PyPegen.get_exprs(p, b)),
            EXTRA) }
    | bitwise_or
compare_op_bitwise_or_pair[CmpopExprPair*]:
    | eq_bitwise_or
    | noteq_bitwise_or
    | lte_bitwise_or
    | lt_bitwise_or
    | gte_bitwise_or
    | gt_bitwise_or
    | notin_bitwise_or
    | in_bitwise_or
    | isnot_bitwise_or
    | is_bitwise_or
eq_bitwise_or[CmpopExprPair*]: '==' a=bitwise_or { $B._PyPegen.cmpop_expr_pair(p, Eq, a) }
noteq_bitwise_or[CmpopExprPair*]:
    | (tok='!=' { $B._PyPegen.check_barry_as_flufl(p, tok) ? NULL : tok}) a=bitwise_or {$B._PyPegen.cmpop_expr_pair(p, NotEq, a) }
lte_bitwise_or[CmpopExprPair*]: '<=' a=bitwise_or { $B._PyPegen.cmpop_expr_pair(p, LtE, a) }
lt_bitwise_or[CmpopExprPair*]: '<' a=bitwise_or { $B._PyPegen.cmpop_expr_pair(p, Lt, a) }
gte_bitwise_or[CmpopExprPair*]: '>=' a=bitwise_or { $B._PyPegen.cmpop_expr_pair(p, GtE, a) }
gt_bitwise_or[CmpopExprPair*]: '>' a=bitwise_or { $B._PyPegen.cmpop_expr_pair(p, Gt, a) }
notin_bitwise_or[CmpopExprPair*]: 'not' 'in' a=bitwise_or { $B._PyPegen.cmpop_expr_pair(p, NotIn, a) }
in_bitwise_or[CmpopExprPair*]: 'in' a=bitwise_or { $B._PyPegen.cmpop_expr_pair(p, In, a) }
isnot_bitwise_or[CmpopExprPair*]: 'is' 'not' a=bitwise_or { $B._PyPegen.cmpop_expr_pair(p, IsNot, a) }
is_bitwise_or[CmpopExprPair*]: 'is' a=bitwise_or { $B._PyPegen.cmpop_expr_pair(p, Is, a) }
bitwise_or[expr_ty]:
    | a=bitwise_or '|' b=bitwise_xor { $B._PyAST.BinOp(a, BitOr, b, EXTRA) }
    | bitwise_xor
bitwise_xor[expr_ty]:
    | a=bitwise_xor '^' b=bitwise_and { $B._PyAST.BinOp(a, BitXor, b, EXTRA) }
    | bitwise_and
bitwise_and[expr_ty]:
    | a=bitwise_and '&' b=shift_expr { $B._PyAST.BinOp(a, BitAnd, b, EXTRA) }
    | shift_expr
shift_expr[expr_ty]:
    | a=shift_expr '<<' b=sum { $B._PyAST.BinOp(a, LShift, b, EXTRA) }
    | a=shift_expr '>>' b=sum { $B._PyAST.BinOp(a, RShift, b, EXTRA) }
    | sum
sum[expr_ty]:
    | a=sum '+' b=term { $B._PyAST.BinOp(a, Add, b, EXTRA) }
    | a=sum '-' b=term { $B._PyAST.BinOp(a, Sub, b, EXTRA) }
    | term
term[expr_ty]:
    | a=term '*' b=factor { $B._PyAST.BinOp(a, Mult, b, EXTRA) }
    | a=term '/' b=factor { $B._PyAST.BinOp(a, Div, b, EXTRA) }
    | a=term '//' b=factor { $B._PyAST.BinOp(a, FloorDiv, b, EXTRA) }
    | a=term '%' b=factor { $B._PyAST.BinOp(a, Mod, b, EXTRA) }
    | a=term '@' b=factor { CHECK_VERSION($B.ast.expr, 5, "The '@' operator is", $B._PyAST.BinOp(a, MatMult, b, EXTRA)) }
    | factor
factor[expr_ty] (memo):
    | '+' a=factor { $B._PyAST.UnaryOp(UAdd, a, EXTRA) }
    | '-' a=factor { $B._PyAST.UnaryOp(USub, a, EXTRA) }
    | '~' a=factor { $B._PyAST.UnaryOp(Invert, a, EXTRA) }
    | power
power[expr_ty]:
    | a=await_primary '**' b=factor { $B._PyAST.BinOp(a, Pow, b, EXTRA) }
    | await_primary
await_primary[expr_ty] (memo):
    | AWAIT a=primary { CHECK_VERSION($B.ast.expr, 5, "Await expressions are", $B._PyAST.Await(a, EXTRA)) }
    | primary
primary[expr_ty]:
    | a=primary '.' b=NAME { $B._PyAST.Attribute(a, b.id, Load, EXTRA) }
    | a=primary b=genexp { $B._PyAST.Call(a, CHECK(asdl_expr_seq, $B._PyPegen.singleton_seq(p, b)), NULL, EXTRA) }
    | a=primary '(' b=[arguments] ')' {
        $B._PyAST.Call(a,
                 (b) ? b.args : NULL,
                 (b) ? b.keywords : NULL,
                 EXTRA) }
    | a=primary '[' b=slices ']' { $B._PyAST.Subscript(a, b, Load, EXTRA) }
    | atom
slices[expr_ty]:
    | a=slice !',' { a }
    | a[asdl_expr_seq*]=','.(slice | starred_expression)+ [','] { $B._PyAST.Tuple(a, Load, EXTRA) }
slice[expr_ty]:
    | a=[expression] ':' b=[expression] c=[':' d=[expression] { d }] { $B._PyAST.Slice(a, b, c, EXTRA) }
    | a=named_expression { a }
atom[expr_ty]:
    | NAME
    | 'True' { $B._PyAST.Constant(Py_True, NULL, EXTRA) }
    | 'False' { $B._PyAST.Constant(Py_False, NULL, EXTRA) }
    | 'None' { $B._PyAST.Constant(Py_None, NULL, EXTRA) }
    | &STRING strings
    | NUMBER
    | &'(' (tuple | group | genexp)
    | &'[' (list | listcomp)
    | &'{' (dict | set | dictcomp | setcomp)
    | '...' { $B._PyAST.Constant(Py_Ellipsis, NULL, EXTRA) }
group[expr_ty]:
    | '(' a=(yield_expr | named_expression) ')' { a }
    | invalid_group
lambdef[expr_ty]:
    | 'lambda' a=[lambda_params] ':' b=expression {
        $B._PyAST.Lambda((a) ? a : CHECK($B.ast.arguments, $B._PyPegen.empty_arguments(p)), b, EXTRA) }
lambda_params[arguments_ty]:
    | invalid_lambda_parameters
    | lambda_parameters
lambda_parameters[arguments_ty]:
    | a=lambda_slash_no_default b[asdl_arg_seq*]=lambda_param_no_default* c=lambda_param_with_default* d=[lambda_star_etc] {
        $B._PyPegen.make_arguments(p, a, NULL, b, c, d) }
    | a=lambda_slash_with_default b=lambda_param_with_default* c=[lambda_star_etc] {
        $B._PyPegen.make_arguments(p, NULL, a, NULL, b, c) }
    | a[asdl_arg_seq*]=lambda_param_no_default+ b=lambda_param_with_default* c=[lambda_star_etc] {
        $B._PyPegen.make_arguments(p, NULL, NULL, a, b, c) }
    | a=lambda_param_with_default+ b=[lambda_star_etc] { $B._PyPegen.make_arguments(p, NULL, NULL, NULL, a, b)}
    | a=lambda_star_etc { $B._PyPegen.make_arguments(p, NULL, NULL, NULL, NULL, a) }
lambda_slash_no_default[asdl_arg_seq*]:
    | a[asdl_arg_seq*]=lambda_param_no_default+ '/' ',' { a }
    | a[asdl_arg_seq*]=lambda_param_no_default+ '/' &':' { a }
lambda_slash_with_default[SlashWithDefault*]:
    | a=lambda_param_no_default* b=lambda_param_with_default+ '/' ',' { $B._PyPegen.slash_with_default(p, a, b) }
    | a=lambda_param_no_default* b=lambda_param_with_default+ '/' &':' { $B._PyPegen.slash_with_default(p, a, b) }
lambda_star_etc[StarEtc*]:
    | invalid_lambda_star_etc
    | '*' a=lambda_param_no_default b=lambda_param_maybe_default* c=[lambda_kwds] {
        $B._PyPegen.star_etc(p, a, b, c) }
    | '*' ',' b=lambda_param_maybe_default+ c=[lambda_kwds] {
        $B._PyPegen.star_etc(p, NULL, b, c) }
    | a=lambda_kwds { $B._PyPegen.star_etc(p, NULL, NULL, a) }
lambda_kwds[arg_ty]:
    | invalid_lambda_kwds
    | '**' a=lambda_param_no_default { a }
lambda_param_no_default[arg_ty]:
    | a=lambda_param ',' { a }
    | a=lambda_param &':' { a }
lambda_param_with_default[NameDefaultPair*]:
    | a=lambda_param c=default ',' { $B._PyPegen.name_default_pair(p, a, c, NULL) }
    | a=lambda_param c=default &':' { $B._PyPegen.name_default_pair(p, a, c, NULL) }
lambda_param_maybe_default[NameDefaultPair*]:
    | a=lambda_param c=default? ',' { $B._PyPegen.name_default_pair(p, a, c, NULL) }
    | a=lambda_param c=default? &':' { $B._PyPegen.name_default_pair(p, a, c, NULL) }
lambda_param[arg_ty]: a=NAME { $B._PyAST.arg(a.id, NULL, NULL, EXTRA) }
strings[expr_ty] (memo): a=STRING+ { $B._PyPegen.concatenate_strings(p, a) }
list[expr_ty]:
    | '[' a=[star_named_expressions] ']' { $B._PyAST.List(a, Load, EXTRA) }
tuple[expr_ty]:
    | '(' a=[y=star_named_expression ',' z=[star_named_expressions] { $B._PyPegen.seq_insert_in_front(p, y, z) } ] ')' {
        $B._PyAST.Tuple(a, Load, EXTRA) }
set[expr_ty]: '{' a=star_named_expressions '}' { $B._PyAST.Set(a, EXTRA) }
dict[expr_ty]:
    | '{' a=[double_starred_kvpairs] '}' {
        $B._PyAST.Dict(
            CHECK(asdl_expr_seq, $B._PyPegen.get_keys(p, a)),
            CHECK(asdl_expr_seq, $B._PyPegen.get_values(p, a)),
            EXTRA) }
    | '{' invalid_double_starred_kvpairs '}'
double_starred_kvpairs[asdl_seq*]: a=','.double_starred_kvpair+ [','] { a }
double_starred_kvpair[KeyValuePair*]:
    | '**' a=bitwise_or { $B._PyPegen.key_value_pair(p, NULL, a) }
    | kvpair
kvpair[KeyValuePair*]: a=expression ':' b=expression { $B._PyPegen.key_value_pair(p, a, b) }
for_if_clauses[asdl_comprehension_seq*]:
    | a[asdl_comprehension_seq*]=for_if_clause+ { a }
for_if_clause[comprehension_ty]:
    | ASYNC 'for' a=star_targets 'in' ~ b=disjunction c[asdl_expr_seq*]=('if' z=disjunction { z })* {
        CHECK_VERSION($B.ast.comprehension, 6, "Async comprehensions are", $B._PyAST.comprehension(a, b, c, 1, p.arena)) }
    | 'for' a=star_targets 'in' ~ b=disjunction c[asdl_expr_seq*]=('if' z=disjunction { z })* {
        $B._PyAST.comprehension(a, b, c, 0, p.arena) }
    | invalid_for_target
listcomp[expr_ty]:
    | '[' a=named_expression b=for_if_clauses ']' { $B._PyAST.ListComp(a, b, EXTRA) }
    | invalid_comprehension
setcomp[expr_ty]:
    | '{' a=named_expression b=for_if_clauses '}' { $B._PyAST.SetComp(a, b, EXTRA) }
    | invalid_comprehension
genexp[expr_ty]:
    | '(' a=( assignment_expression | expression !':=') b=for_if_clauses ')' { $B._PyAST.GeneratorExp(a, b, EXTRA) }
    | invalid_comprehension
dictcomp[expr_ty]:
    | '{' a=kvpair b=for_if_clauses '}' { $B._PyAST.DictComp(a.key, a.value, b, EXTRA) }
    | invalid_dict_comprehension
arguments[expr_ty] (memo):
    | a=args [','] &')' { a }
    | invalid_arguments
args[expr_ty]:
    | a[asdl_expr_seq*]=','.(starred_expression | ( assignment_expression | expression !':=') !'=')+ b=[',' k=kwargs {k}] {
        $B._PyPegen.collect_call_seqs(p, a, b, EXTRA) }
    | a=kwargs { $B._PyAST.Call($B._PyPegen.dummy_name(p),
                          CHECK_NULL_ALLOWED(asdl_expr_seq, $B._PyPegen.seq_extract_starred_exprs(p, a)),
                          CHECK_NULL_ALLOWED(asdl_keyword_seq, $B._PyPegen.seq_delete_starred_exprs(p, a)),
                          EXTRA) }
kwargs[asdl_seq*]:
    | a=','.kwarg_or_starred+ ',' b=','.kwarg_or_double_starred+ { $B._PyPegen.join_sequences(p, a, b) }
    | ','.kwarg_or_starred+
    | ','.kwarg_or_double_starred+
starred_expression[expr_ty]:
    | '*' a=expression { $B._PyAST.Starred(a, Load, EXTRA) }
kwarg_or_starred[KeywordOrStarred*]:
    | invalid_kwarg
    | a=NAME '=' b=expression {
        $B._PyPegen.keyword_or_starred(p, CHECK($B.ast.keyword, $B._PyAST.keyword(a.id, b, EXTRA)), 1) }
    | a=starred_expression { $B._PyPegen.keyword_or_starred(p, a, 0) }
kwarg_or_double_starred[KeywordOrStarred*]:
    | invalid_kwarg
    | a=NAME '=' b=expression {
        $B._PyPegen.keyword_or_starred(p, CHECK($B.ast.keyword, $B._PyAST.keyword(a.id, b, EXTRA)), 1) }
    | '**' a=expression { $B._PyPegen.keyword_or_starred(p, CHECK($B.ast.keyword, $B._PyAST.keyword(NULL, a, EXTRA)), 1) }
star_targets[expr_ty]:
    | a=star_target !',' { a }
    | a=star_target b=(',' c=star_target { c })* [','] {
        $B._PyAST.Tuple(CHECK(asdl_expr_seq, $B._PyPegen.seq_insert_in_front(p, a, b)), Store, EXTRA) }
star_targets_list_seq[asdl_expr_seq*]: a[asdl_expr_seq*]=','.star_target+ [','] { a }
star_targets_tuple_seq[asdl_expr_seq*]:
    | a=star_target b=(',' c=star_target { c })+ [','] { (asdl_expr_seq) $B._PyPegen.seq_insert_in_front(p, a, b) }
    | a=star_target ',' { (asdl_expr_seq) $B._PyPegen.singleton_seq(p, a) }
star_target[expr_ty] (memo):
    | '*' a=(!'*' star_target) {
        $B._PyAST.Starred(CHECK($B.ast.expr, $B._PyPegen.set_expr_context(p, a, Store)), Store, EXTRA) }
    | target_with_star_atom
target_with_star_atom[expr_ty] (memo):
    | a=t_primary '.' b=NAME !t_lookahead { $B._PyAST.Attribute(a, b.id, Store, EXTRA) }
    | a=t_primary '[' b=slices ']' !t_lookahead { $B._PyAST.Subscript(a, b, Store, EXTRA) }
    | star_atom
star_atom[expr_ty]:
    | a=NAME { $B._PyPegen.set_expr_context(p, a, Store) }
    | '(' a=target_with_star_atom ')' { $B._PyPegen.set_expr_context(p, a, Store) }
    | '(' a=[star_targets_tuple_seq] ')' { $B._PyAST.Tuple(a, Store, EXTRA) }
    | '[' a=[star_targets_list_seq] ']' { $B._PyAST.List(a, Store, EXTRA) }
single_target[expr_ty]:
    | single_subscript_attribute_target
    | a=NAME { $B._PyPegen.set_expr_context(p, a, Store) }
    | '(' a=single_target ')' { a }
single_subscript_attribute_target[expr_ty]:
    | a=t_primary '.' b=NAME !t_lookahead { $B._PyAST.Attribute(a, b.id, Store, EXTRA) }
    | a=t_primary '[' b=slices ']' !t_lookahead { $B._PyAST.Subscript(a, b, Store, EXTRA) }
t_primary[expr_ty]:
    | a=t_primary '.' b=NAME &t_lookahead { $B._PyAST.Attribute(a, b.id, Load, EXTRA) }
    | a=t_primary '[' b=slices ']' &t_lookahead { $B._PyAST.Subscript(a, b, Load, EXTRA) }
    | a=t_primary b=genexp &t_lookahead {
        $B._PyAST.Call(a, CHECK(asdl_expr_seq, $B._PyPegen.singleton_seq(p, b)), NULL, EXTRA) }
    | a=t_primary '(' b=[arguments] ')' &t_lookahead {
        $B._PyAST.Call(a,
                 (b) ? b.args : NULL,
                 (b) ? b.keywords : NULL,
                 EXTRA) }
    | a=atom &t_lookahead { a }
t_lookahead: '(' | '[' | '.'
del_targets[asdl_expr_seq*]: a[asdl_expr_seq*]=','.del_target+ [','] { a }
del_target[expr_ty] (memo):
    | a=t_primary '.' b=NAME !t_lookahead { $B._PyAST.Attribute(a, b.id, Del, EXTRA) }
    | a=t_primary '[' b=slices ']' !t_lookahead { $B._PyAST.Subscript(a, b, Del, EXTRA) }
    | del_t_atom
del_t_atom[expr_ty]:
    | a=NAME { $B._PyPegen.set_expr_context(p, a, Del) }
    | '(' a=del_target ')' { $B._PyPegen.set_expr_context(p, a, Del) }
    | '(' a=[del_targets] ')' { $B._PyAST.Tuple(a, Del, EXTRA) }
    | '[' a=[del_targets] ']' { $B._PyAST.List(a, Del, EXTRA) }
type_expressions[asdl_expr_seq*]:
    | a=','.expression+ ',' '*' b=expression ',' '**' c=expression {
        $B._PyPegen.seq_append_to_end(
            p,
            CHECK(asdl_seq, $B._PyPegen.seq_append_to_end(p, a, b)),
            c) }
    | a=','.expression+ ',' '*' b=expression { $B._PyPegen.seq_append_to_end(p, a, b) }
    | a=','.expression+ ',' '**' b=expression { $B._PyPegen.seq_append_to_end(p, a, b) }
    | '*' a=expression ',' '**' b=expression {
        $B._PyPegen.seq_append_to_end(
            p,
            CHECK(asdl_seq, $B._PyPegen.singleton_seq(p, a)),
            b) }
    | '*' a=expression { $B._PyPegen.singleton_seq(p, a) }
    | '**' a=expression { $B._PyPegen.singleton_seq(p, a) }
    | a[asdl_expr_seq*]=','.expression+ {a}
func_type_comment[Token*]:
    | NEWLINE t=TYPE_COMMENT &(NEWLINE INDENT) { t }  # Must be followed by indented block
    | invalid_double_type_comments
    | TYPE_COMMENT
invalid_arguments:
    | a=args ',' '*' { RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "iterable argument unpacking follows keyword argument unpacking") }
    | a=expression b=for_if_clauses ',' [args | expression for_if_clauses] {
        RAISE_SYNTAX_ERROR_KNOWN_RANGE(a, $B._PyPegen.get_last_comprehension_item(PyPegen_last_item(b, $B.ast.comprehension)), "Generator expression must be parenthesized") }
    | a=NAME b='=' expression for_if_clauses {
        RAISE_SYNTAX_ERROR_KNOWN_RANGE(a, b, "invalid syntax. Maybe you meant '==' or ':=' instead of '='?")}
    | a=args b=for_if_clauses { $B._PyPegen.nonparen_genexp_in_call(p, a, b) }
    | args ',' a=expression b=for_if_clauses {
        RAISE_SYNTAX_ERROR_KNOWN_RANGE(a, $B._PyPegen.get_last_comprehension_item(PyPegen_last_item(b, $B.ast.comprehension)), "Generator expression must be parenthesized") }
    | a=args ',' args { $B._PyPegen.arguments_parsing_error(p, a) }
invalid_kwarg:
    | a[Token*]=('True'|'False'|'None') b='=' {
        RAISE_SYNTAX_ERROR_KNOWN_RANGE(a, b, "cannot assign to %s", PyBytes_AS_STRING(a.bytes)) }
    | a=NAME b='=' expression for_if_clauses {
        RAISE_SYNTAX_ERROR_KNOWN_RANGE(a, b, "invalid syntax. Maybe you meant '==' or ':=' instead of '='?")}
    | !(NAME '=') a=expression b='=' {
        RAISE_SYNTAX_ERROR_KNOWN_RANGE(
            a, b, "expression cannot contain assignment, perhaps you meant \"==\"?") }
expression_without_invalid[expr_ty]:
    | a=disjunction 'if' b=disjunction 'else' c=expression { $B._PyAST.IfExp(b, a, c, EXTRA) }
    | disjunction
    | lambdef
invalid_legacy_expression:
    | a=NAME !'(' b=star_expressions {
        $B._PyPegen.check_legacy_stmt(p, a) ? RAISE_SYNTAX_ERROR_KNOWN_RANGE(a, b,
            "Missing parentheses in call to '%U'. Did you mean %U(...)?", a.id, a.id) : NULL}
invalid_expression:
    # !(NAME STRING) is not matched so we don't show this error with some invalid string prefixes like: kf"dsfsdf"
    # Soft keywords need to also be ignored because they can be parsed as NAME NAME
   | !(NAME STRING | SOFT_KEYWORD) a=disjunction b=expression_without_invalid {
        $B._PyPegen.check_legacy_stmt(p, a) ? NULL : p.tokens[p.mark-1].level == 0 ? NULL :
        RAISE_SYNTAX_ERROR_KNOWN_RANGE(a, b, "invalid syntax. Perhaps you forgot a comma?") }
   | a=disjunction 'if' b=disjunction !('else'|':') { RAISE_SYNTAX_ERROR_KNOWN_RANGE(a, b, "expected 'else' after 'if' expression") }
invalid_named_expression(memo):
    | a=expression ':=' expression {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(
            a, "cannot use assignment expressions with %s", $B._PyPegen.get_expr_name(a)) }
    | a=NAME '=' b=bitwise_or !('='|':=') {
        RAISE_SYNTAX_ERROR_KNOWN_RANGE(a, b, "invalid syntax. Maybe you meant '==' or ':=' instead of '='?") }
    | !(list|tuple|genexp|'True'|'None'|'False') a=bitwise_or b='=' bitwise_or !('='|':=') {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "cannot assign to %s here. Maybe you meant '==' instead of '='?",
                                          $B._PyPegen.get_expr_name(a)) }
invalid_assignment:
    | a=invalid_ann_assign_target ':' expression {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(
            a,
            "only single target (not %s) can be annotated",
            $B._PyPegen.get_expr_name(a)
        )}
    | a=star_named_expression ',' star_named_expressions* ':' expression {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "only single target (not tuple) can be annotated") }
    | a=expression ':' expression {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "illegal target for annotation") }
    | (star_targets '=')* a=star_expressions '=' {
        RAISE_SYNTAX_ERROR_INVALID_TARGET(STAR_TARGETS, a) }
    | (star_targets '=')* a=yield_expr '=' { RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "assignment to yield expression not possible") }
    | a=star_expressions augassign (yield_expr | star_expressions) {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(
            a,
            "'%s' is an illegal expression for augmented assignment",
            $B._PyPegen.get_expr_name(a)
        )}
invalid_ann_assign_target[expr_ty]:
    | list
    | tuple
    | '(' a=invalid_ann_assign_target ')' { a }
invalid_del_stmt:
    | 'del' a=star_expressions {
        RAISE_SYNTAX_ERROR_INVALID_TARGET(DEL_TARGETS, a) }
invalid_block:
    | NEWLINE !INDENT { RAISE_INDENTATION_ERROR("expected an indented block") }
invalid_comprehension:
    | ('[' | '(' | '{') a=starred_expression for_if_clauses {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "iterable unpacking cannot be used in comprehension") }
    | ('[' | '{') a=star_named_expression ',' b=star_named_expressions for_if_clauses {
        RAISE_SYNTAX_ERROR_KNOWN_RANGE(a, PyPegen_last_item(b, $B.ast.expr),
        "did you forget parentheses around the comprehension target?") }
    | ('[' | '{') a=star_named_expression b=',' for_if_clauses {
        RAISE_SYNTAX_ERROR_KNOWN_RANGE(a, b, "did you forget parentheses around the comprehension target?") }
invalid_dict_comprehension:
    | '{' a='**' bitwise_or for_if_clauses '}' {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "dict unpacking cannot be used in dict comprehension") }
invalid_parameters:
    | param_no_default* invalid_parameters_helper a=param_no_default {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "non-default argument follows default argument") }
    | param_no_default* a='(' param_no_default+ ','? b=')' {
        RAISE_SYNTAX_ERROR_KNOWN_RANGE(a, b, "Function parameters cannot be parenthesized") }
    | a="/" ',' {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "at least one argument must precede /") }
    | (slash_no_default | slash_with_default) param_maybe_default* a='/' {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "/ may appear only once") }
    | (slash_no_default | slash_with_default)? param_maybe_default* '*' (',' | param_no_default) param_maybe_default* a='/' {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "/ must be ahead of *") }
    | param_maybe_default+ '/' a='*' {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "expected comma between / and *") }
invalid_default:
    | a='=' &(')'|',') { RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "expected default value expression") }
invalid_star_etc:
    | a='*' (')' | ',' (')' | '**')) { RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "named arguments must follow bare *") }
    | '*' ',' TYPE_COMMENT { RAISE_SYNTAX_ERROR("bare * has associated type comment") }
    | '*' param a='=' { RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "var-positional argument cannot have default value") }
    | '*' (param_no_default | ',') param_maybe_default* a='*' (param_no_default | ',') {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "* argument may appear only once") }
invalid_kwds:
    | '**' param a='=' { RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "var-keyword argument cannot have default value") }
    | '**' param ',' a=param { RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "arguments cannot follow var-keyword argument") }
    | '**' param ',' a[Token*]=('*'|'**'|'/') { RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "arguments cannot follow var-keyword argument") }
invalid_parameters_helper: # This is only there to avoid type errors
    | a=slash_with_default { $B._PyPegen.singleton_seq(p, a) }
    | param_with_default+
invalid_lambda_parameters:
    | lambda_param_no_default* invalid_lambda_parameters_helper a=lambda_param_no_default {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "non-default argument follows default argument") }
    | lambda_param_no_default* a='(' ','.lambda_param+ ','? b=')' {
        RAISE_SYNTAX_ERROR_KNOWN_RANGE(a, b, "Lambda expression parameters cannot be parenthesized") }
    | a="/" ',' {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "at least one argument must precede /") }
    | (lambda_slash_no_default | lambda_slash_with_default) lambda_param_maybe_default* a='/' {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "/ may appear only once") }
    | (lambda_slash_no_default | lambda_slash_with_default)? lambda_param_maybe_default* '*' (',' | lambda_param_no_default) lambda_param_maybe_default* a='/' {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "/ must be ahead of *") }
    | lambda_param_maybe_default+ '/' a='*' {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "expected comma between / and *") }
invalid_lambda_parameters_helper:
    | a=lambda_slash_with_default { $B._PyPegen.singleton_seq(p, a) }
    | lambda_param_with_default+
invalid_lambda_star_etc:
    | '*' (':' | ',' (':' | '**')) { RAISE_SYNTAX_ERROR("named arguments must follow bare *") }
    | '*' lambda_param a='=' { RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "var-positional argument cannot have default value") }
    | '*' (lambda_param_no_default | ',') lambda_param_maybe_default* a='*' (lambda_param_no_default | ',') {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "* argument may appear only once") }
invalid_lambda_kwds:
    | '**' lambda_param a='=' { RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "var-keyword argument cannot have default value") }
    | '**' lambda_param ',' a=lambda_param { RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "arguments cannot follow var-keyword argument") }
    | '**' lambda_param ',' a[Token*]=('*'|'**'|'/') { RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "arguments cannot follow var-keyword argument") }
invalid_double_type_comments:
    | TYPE_COMMENT NEWLINE TYPE_COMMENT NEWLINE INDENT {
        RAISE_SYNTAX_ERROR("Cannot have two type comments on def") }
invalid_with_item:
    | expression 'as' a=expression &(',' | ')' | ':') {
        RAISE_SYNTAX_ERROR_INVALID_TARGET(STAR_TARGETS, a) }
invalid_for_target:
    | ASYNC? 'for' a=star_expressions {
        RAISE_SYNTAX_ERROR_INVALID_TARGET(FOR_TARGETS, a) }
invalid_group:
    | '(' a=starred_expression ')' {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "cannot use starred expression here") }
    | '(' a='**' expression ')' {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "cannot use double starred expression here") }
invalid_import_from_targets:
    | import_from_as_names ',' NEWLINE {
        RAISE_SYNTAX_ERROR("trailing comma not allowed without surrounding parentheses") }
invalid_with_stmt:
    | [ASYNC] 'with' ','.(expression ['as' star_target])+ &&':'
    | [ASYNC] 'with' '(' ','.(expressions ['as' star_target])+ ','? ')' &&':'
invalid_with_stmt_indent:
    | [ASYNC] a='with' ','.(expression ['as' star_target])+ ':' NEWLINE !INDENT {
        RAISE_INDENTATION_ERROR("expected an indented block after 'with' statement on line %d", a.lineno) }
    | [ASYNC] a='with' '(' ','.(expressions ['as' star_target])+ ','? ')' ':' NEWLINE !INDENT {
        RAISE_INDENTATION_ERROR("expected an indented block after 'with' statement on line %d", a.lineno) }
invalid_try_stmt:
    | a='try' ':' NEWLINE !INDENT {
        RAISE_INDENTATION_ERROR("expected an indented block after 'try' statement on line %d", a.lineno) }
    | 'try' ':' block !('except' | 'finally') { RAISE_SYNTAX_ERROR("expected 'except' or 'finally' block") }
    | 'try' ':' block* ((except_block+ except_star_block) | (except_star_block+ except_block)) block* {
        RAISE_SYNTAX_ERROR("cannot have both 'except' and 'except' on the same 'try'") }
invalid_except_stmt:
    | 'except' '*'? a=expression ',' expressions ['as' NAME ] ':' {
        RAISE_SYNTAX_ERROR_STARTING_FROM(a, "multiple exception types must be parenthesized") }
    | a='except' '*'? expression ['as' NAME ] NEWLINE { RAISE_SYNTAX_ERROR("expected ':'") }
    | a='except' NEWLINE { RAISE_SYNTAX_ERROR("expected ':'") }
    | a='except' '*' (NEWLINE | ':') { RAISE_SYNTAX_ERROR("expected one or more exception types") }
invalid_finally_stmt:
    | a='finally' ':' NEWLINE !INDENT {
        RAISE_INDENTATION_ERROR("expected an indented block after 'finally' statement on line %d", a.lineno) }
invalid_except_stmt_indent:
    | a='except' expression ['as' NAME ] ':' NEWLINE !INDENT {
        RAISE_INDENTATION_ERROR("expected an indented block after 'except' statement on line %d", a.lineno) }
    | a='except' ':' NEWLINE !INDENT { RAISE_INDENTATION_ERROR("expected an indented block after 'except' statement on line %d", a.lineno) }
invalid_except_star_stmt_indent:
    | a='except' '*' expression ['as' NAME ] ':' NEWLINE !INDENT {
        RAISE_INDENTATION_ERROR("expected an indented block after 'except' statement on line %d", a.lineno) }
invalid_match_stmt:
    | "match" subject_expr !':' { CHECK_VERSION(void, 10, "Pattern matching is", RAISE_SYNTAX_ERROR("expected ':'") ) }
    | a="match" subject=subject_expr ':' NEWLINE !INDENT {
        RAISE_INDENTATION_ERROR("expected an indented block after 'match' statement on line %d", a.lineno) }
invalid_case_block:
    | "case" patterns guard? !':' { RAISE_SYNTAX_ERROR("expected ':'") }
    | a="case" patterns guard? ':' NEWLINE !INDENT {
        RAISE_INDENTATION_ERROR("expected an indented block after 'case' statement on line %d", a.lineno) }
invalid_as_pattern:
    | or_pattern 'as' a="_" { RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "cannot use '_' as a target") }
    | or_pattern 'as' !NAME a=expression { RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "invalid pattern target") }
invalid_class_pattern:
    | name_or_attr '(' a=invalid_class_argument_pattern  { RAISE_SYNTAX_ERROR_KNOWN_RANGE(
        PyPegen_first_item(a, $B.ast.pattern),
        PyPegen_last_item(a, $B.ast.pattern),
        "positional patterns follow keyword patterns") }
invalid_class_argument_pattern[asdl_pattern_seq*]:
    | [positional_patterns ','] keyword_patterns ',' a=positional_patterns { a }
invalid_if_stmt:
    | 'if' named_expression NEWLINE { RAISE_SYNTAX_ERROR("expected ':'") }
    | a='if' a=named_expression ':' NEWLINE !INDENT {
        RAISE_INDENTATION_ERROR("expected an indented block after 'if' statement on line %d", a.lineno) }
invalid_elif_stmt:
    | 'elif' named_expression NEWLINE { RAISE_SYNTAX_ERROR("expected ':'") }
    | a='elif' named_expression ':' NEWLINE !INDENT {
        RAISE_INDENTATION_ERROR("expected an indented block after 'elif' statement on line %d", a.lineno) }
invalid_else_stmt:
    | a='else' ':' NEWLINE !INDENT {
        RAISE_INDENTATION_ERROR("expected an indented block after 'else' statement on line %d", a.lineno) }
invalid_while_stmt:
    | 'while' named_expression NEWLINE { RAISE_SYNTAX_ERROR("expected ':'") }
    | a='while' named_expression ':' NEWLINE !INDENT {
        RAISE_INDENTATION_ERROR("expected an indented block after 'while' statement on line %d", a.lineno) }
invalid_for_stmt:
    | [ASYNC] a='for' star_targets 'in' star_expressions ':' NEWLINE !INDENT {
        RAISE_INDENTATION_ERROR("expected an indented block after 'for' statement on line %d", a.lineno) }
invalid_def_raw:
    | [ASYNC] a='def' NAME '(' [params] ')' ['->' expression] ':' NEWLINE !INDENT {
        RAISE_INDENTATION_ERROR("expected an indented block after function definition on line %d", a.lineno) }
invalid_class_def_raw:
    | a='class' NAME ['('[arguments] ')'] ':' NEWLINE !INDENT {
        RAISE_INDENTATION_ERROR("expected an indented block after class definition on line %d", a.lineno) }
invalid_double_starred_kvpairs:
    | ','.double_starred_kvpair+ ',' invalid_kvpair
    | expression ':' a='*' bitwise_or { RAISE_SYNTAX_ERROR_STARTING_FROM(a, "cannot use a starred expression in a dictionary value") }
    | expression a=':' &('}'|',') { RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "expression expected after dictionary key and ':'") }
invalid_kvpair:
    | a=expression !(':') {
        RAISE_ERROR_KNOWN_LOCATION(p, PyExc_SyntaxError, a.lineno, a.end_col_offset - 1, a.end_lineno, -1, "':' expected after dictionary key") }
    | expression ':' a='*' bitwise_or { RAISE_SYNTAX_ERROR_STARTING_FROM(a, "cannot use a starred expression in a dictionary value") }
    | expression a=':' {RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "expression expected after dictionary key and ':'") }
